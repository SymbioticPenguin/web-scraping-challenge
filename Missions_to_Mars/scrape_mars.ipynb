{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### We are starting by scraping the NASA website for the latest news update. We are also scraping twitter for\n",
    "###### the latest weather report on Mars.\n",
    "\n",
    "# NASA news URL\n",
    "news_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "# Twitter URL for weather\n",
    "twitter = \"https://twitter.com/marswxreport?lang=en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting HTML from websites\n",
    "response = requests.get(news_url)\n",
    "weather_tweet = requests.get(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASA soup\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "# Twitter soup\n",
    "bird_soup = BeautifulSoup(weather_tweet.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the scraping of various sites happens\n",
    "\n",
    "# NASA website for news headline and flavor text\n",
    "titles = soup.find_all('div', class_=\"content_title\")\n",
    "paragraphs = soup.find_all('div', class_ = \"image_and_description_container\")\n",
    "\n",
    "# Twitter for the weather update\n",
    "all_weather = bird_soup.find('div', class_ = 'js-tweet-text-container')\n",
    "\n",
    "###### Finishing the scrape job of NASA and Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Starting the scraping of the \"Mars Facts Data table\"\n",
    "\n",
    "# Mars facts URL\n",
    "facts = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Reading fact table from Mars Facts URL\n",
    "fact_table = pd.read_html(facts)[0].rename(columns = {0:\"Metric\",1:\"Value\"}).set_index(\"Metric\")\n",
    "\n",
    "###### Finishing the scrape of the basic data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Defining all the variables that will go into MongoDB later\n",
    "\n",
    "# Title\n",
    "news_title = titles[0].find('a').text.replace(\"\\n\",\"\")\n",
    "\n",
    "# Flavor text of article\n",
    "news_p = paragraphs[0].find('div',class_ = 'rollover_description_inner').text.replace(\"\\n\",\"\").replace(\"\\\"\",'')\n",
    "\n",
    "### URL for image on JPL website (Hard coded?)\n",
    "img_url = \"https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA14293_ip.jpg\"\n",
    "\n",
    "# This gives the tweet for the latest weather update. If there is a picture, the scrape trashes the pic URL\n",
    "# from the string.\n",
    "one_weather = all_weather.find('p').text.replace(\"\\n\",\"\").replace(\"\\\"\",'')\n",
    "\n",
    "if(\"pic.twitter\" in one_weather):\n",
    "    one_weather = one_weather[:one_weather.find(\"pic.twitter\")]\n",
    "    \n",
    "\n",
    "# create the dictionary with the URL to the pictures of the 4 hemispheres of Mars\n",
    "\n",
    "hemi_pics = [{'title':'Cerberus Hemisphere','url':'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
    "               {'title':'Schiaparelli Hemisphere','url':'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
    "               {'title':'Syrtis Major Hemisphere','url':'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
    "               {'title':'Valles Marineris Hemisphere','url':'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Final Dictionary that will be depoloyed through MONGO\n",
    "\n",
    "big_boy_book = {\"title\":news_title,\n",
    "               \"news\":news_p,\n",
    "               'main_img':img_url,\n",
    "               'weather':one_weather,\n",
    "               'hemi_pics':hemi_pics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
